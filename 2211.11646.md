
NeRF-RPN: A general framework for object detection in NeRFs


Instead of trying to detect on images, they do 3D on 3D.

Contributions:

 First significant attempt on introducing RPN to NeRF
for 3D objection detection and related tasks.


Octrees??

Anchor-based methods in C\N's

3D Object Detection with multiple cameras

3D object detection can be point cloud-based or RGB-based
Usually things get turned into voxels, but now even raw point clouds are being used.

With one camera:


Crust : point cloud samples which cover only the surface of an object

First, they take a raw radiance and density vocel grid from a NerF model and produces a feature pyramid.

Then they use an RPN to operate on the feature pyramid and generate an object proposal.

Different NERF variants can have different radiance field structures, but they all can be queried with view directions and spatial locations. AKA

$o$


Spherical harmonics are a form of radiance representation?

Three backbones they use:

VGG
ResNet
Swin Transformer


They use an FPN to make up for the variation in object sizes in indoor scenes.

They also use 3D convolutions instead of 2D ones with position embedding and shifted windows.

OBB - oriented bounding boxes

rotation of bounding boxes is constrained to z-axis only which is perpendicular to the ground and aligned with gravity.


Faster R-C \N - places anchors at different locations and with different sizes


there are k anchors in total
Two 1x1 convolutional layers predict the probability p that an objevt exissta and the bounding box offset t for each anchor.


los =s is a combinato=ion of binary cross entropy loss for objectness and smooth L_1 loss.

t is the bounding box offset

FCOS is the anchor free method used for the Region Proposal Network


FCOS-based RPN predicts p, t, and a centerness score c for each voxel


trilinear interpolation???

What the hell is the bounding box offset 
$g = (gx, gy , gz , gw, gl, gh, gÎ¸ )$

2D projection loss does not improve performance?

Why did they add it?




Thus, we perform extensive cleaning
based on both the NeRF reconstruction quality and the
usability of object annotations (supp mtrl)

supp mrl???


Oh, supplementary material.


They chose the sharpest frame based on the variance of the Laplacian\ldots

What??


What does 


a maximum
resolution of 200 for the longest dimension of NeRF
sampling grids for Hypersim,

mean for a Nerf?


They use AdamW. How is this different from Adam?o


Anchor-free models are doing better somehoww\ldots

They show failure cases.
