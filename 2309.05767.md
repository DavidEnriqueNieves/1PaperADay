
## Name
NATURAL LANGUAGE SUPERVISION FOR GENERAL-PURPOSE AUDIO
REPRESENTATIONS
## Purpose of study
To showcase a new CLAP model with innovative encoders.
## Research questions
How can we enable joint representations of audio and text?
How can we classify audio?
How can we obtain text-based audio representations?
## conceptual/theoretical framework used
Transformers, Contrastive Language Audio Pretraining
## bodies of literature cited in lit review
## methodology, if stated or can be inferred
Trained encoder and decoder separately
CLAP (Contrastive Language-Audio Pretraining) - jointly trains an audio and a text encoder to learn multimodal representations for different types of inference

Traained CLAP model with 4.6million audio-text pairs and evaluated the generalization on 26 downstream tasks, achieving SoTA results

For the audio encoder, used HTSAT on 22 tasks 

For the text encoder, they adapted GPT-2

## methods (site, sample, participants or whatever it may be)
## findings
Meh
## resulting arguments
## implications
## conclusion

