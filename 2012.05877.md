
# iNeRF: Inverting Neural Radiance Fields for Pose Estimation
(https://arxiv.org/pdf/2012.05877.pdf)


## First pass
Dataset used is LLFF?

They use iNerF to train on NerF by taking the outputs from NerFs from images of
the scene and then using those outputs and the image pixels as inputs to a NerF
as ground truth data.

Type of pose estimation done here is called 6DoF pose estimation.

analysis-by-synthesis

Xu Chen, Zijian Dong, Jie Song, Andreas Geiger, and Otmar Hilliges.
Category level object pose estimation via neural analysis-by-synthesis.
ECCV, 2020.

Wei-Chiu Ma, Shenlong Wang, Jiayuan Gu, Sivabalan Manivasagam,
Antonio Torralba, and Raquel Urtasun. Deep feedback inverse problem
solver. ECCV, 2020.

Keunhong Park, Arsalan Mousavian, Yu Xiang, and Dieter Fox.
Latentfusion: End-to-end differentiable reconstruction and rendering
for unseen object pose estimation. CVPR, 2020.

Gu Wang, Fabian Manhardt, Jianzhun Shao, Xiangyang Ji, Nassir
Navab, and Federico Tombari. Self6d: Self-supervised monocular 6d
object pose estimation. arXiv preprint arXiv:2004.06468, 2020

Problem with differentiable rendering engines is that they requre an accurate 3D model. 
Why?

Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul Srinivasan,
Howard Zhou, Jonathan T. Barron, Ricardo Martin-Brualla, Noah
Snavely, and Thomas Funkhouser. Ibrnet: Learning multi-view image-
based rendering. arXiv preprint arXiv:2102.13090, 2021.

Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa. pixel-
nerf: Neural radiance fields from one or few images. CVPR, 2021


Naturally, they don't sample *all* the pixels, but rather a sub-sample of them in what can be called an interest point-based sampling approach.

What does category-level pose estimation mean??

Xu Chen, Zijian Dong, Jie Song, Andreas Geiger, and Otmar Hilliges.
Category level object pose estimation via neural analysis-by-synthesis.
ECCV, 2020

Contributions:

- iNerF can use a NerF to obtain  a 6DoF pose from an image using a NerF
- analyze and optimize batch size to see the limitations
- show that iNerF can improve NerF by predicting camera poses
- category-level pose estimation results for unseen objects

^ What does category-level mean??

## Second pass


Neural networks can be optimized to represent the signed distance function or occupancy function


Could be a useful survey?

Hiroharu Kato, Deniz Beker, Mihai Morariu, Takahiro Ando, Toru
Matsuoka, Wadim Kehl, and Adrien Gaidon. Differentiable rendering:
A survey. arXiv preprint arXiv:2006.12057, 2020.


Chen-Hsuan Lin, Chaoyang Wang, and Simon Lucey. Sdf-srn:
Learning signed distance 3d object reconstruction from static images.
NeurIPS, 2020.

Chen-Hsuan Lin, Oliver Wang, Bryan C Russell, Eli Shechtman,
Vladimir G Kim, Matthew Fisher, and Simon Lucey. Photometric
mesh optimization for video-aligned 3d object reconstruction. In
Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 969–978, 2019


NerF in the wild mainly models images appearance and transient content, allowing people to reconstruct from images in the wild

NSVF implements a sparse voxel octree to aceelerate rendering by allowing voxels without content to be omitted during rendering

PoseCNN is one type of CNN that can estimate poses.

Other methods estimate keypoints and solve for the pose using the PnP-RANSAC algorithm
Look this up!


He Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran
Song, and Leonidas J Guibas. Normalized object coordinate space for
category-level 6d object pose and size estimation. CVPR, 2019.


RGB images are usually labelled as $\left{ I_i \right}^N_{i=1}$

 $I_i \in [0,1]^{H \cprod W \cprod 3}$

 Poses are  ${T_i}^N_{i=1}$

Lookup how to do bold symbols in Latex


unit-norm viewing direction is  \[
d = (d_x, d_y , d_z)
.\] 



Volume rendering is discussed here:
Nelson Max. Optical models for direct volume rendering. IEEE TVCG,
1995

and here

James T. Kajiya and Brian P. Von Herzen. Ray tracing volume
densities. SIGGRAPH, 1984


Why do they need the camera intrinsics??

SE3 pops up again

They use same photometric loss as used in NerF

They do 

\[
\frac{\partial \mathcal{L}}{\partial T} \text{instead of } \frac{\partial \mathcal{L} }{\partial \Theta }
.\] 


Eucledian isometry can be direct or indirect depending on wehther it preserves the handedness of figures

SE(3) stands for the special eucledian group or the direct eucledian isometries

Isometry - distance preserving transformation between metric spaces


How would the pose $ \hat{T_i}$ fall outside of the SE(3) manifold during gradient optimization?

Why do you even need a manifold for the pose? (is it because of the shape of the Earth?)

*sigh* 

What does this representation mean?

Oh, is it from Rodrigues' formula for an angle-axis vector representation???
Not exactly...

What is the screw axis??

Apparently it's the line that is the axis of rotation and the line along with a rotation occurs?

(I guess I have to read this reference for more details)

Kevin M Lynch and Frank C Park. Modern Robotics. Cambridge
University Press, 2017

Random sampling of rays is not very useful.

Interest point sampling is useful

Interest region - uses points from interest point detector and applies a 5 x 5 morpholical dilation to enlarge the region (???)


Metric used in the pose estimation community is percentage of predicter poses whose error is less than 5 degrees and whose translations are less than 5cm

Larger batch sizes achieve better pose estimation accuracy and faster convergence.


What is a normalized device coordinte space??

SuperGlue is a feature-based baseline for comparing feature matching with a graph neural network


They use a pixelNeRF model trained on synthetic ShapeNet dataset to infer the model

PointRend - background remover 

Lighting and occlusion severely affect performance!

They could use NerF-W by using transient latent codes as in NerF-W?

iNerf takes 20 seconds to run 100 steps, which is not practical



## Summary

1. Category: What type of paper is this? A measure-
ment paper? An analysis of an existing system? A
description of a research prototype?

This is a algorithm paper that uses NerFs for pose estimation given an image.

2. Context: Which other papers is it related to? Which
theoretical bases were used to analyze the problem?

It is related to other NerF papers. It technically is one of the first of its kind, but there are others baselines that they compare it to such as SuperGlue.



3. Correctness: Do the assumptions appear to be valid?

While they don't state this explicitly, their approach depends on the NerF that is being used, which in turn adds some assumptions about how feasible a pose extraction from an image is based on the actual environmental (mainly lighting) conditions. 

4. Contributions: What are the paper’s main contribu-
tions?

- They developed a way to obtain an accurate pose estimate from a NerF, thus serving as an inverse function for it
- They looked at ways of batching rays for performing backpropagation on the image to obtain a pose and found that there are some effective ways of doing so
- They showed that they can use iNerF's outputs as input data to a NerF to train it
- They can perform pose estimation for unseen objects? (still unclear on that part)

5. Clarity: Is the paper well written?

Yes, I think so.

6. Datasets

LLFF


ShapeNet

Synthetic NerF dataset




